{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61935599-443c-402a-87ea-6dfb4328b15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-6164d1e8966047c3b6dce757de501676\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6164d1e8966047c3b6dce757de501676\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6164d1e8966047c3b6dce757de501676\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"color\": \"#0ead69\"}, \"encoding\": {\"x\": {\"axis\": {\"tickMinStep\": 1}, \"field\": \"node_id\", \"title\": \"Node ID\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"tickMinStep\": 100}, \"field\": \"gpu_mem_mb\", \"title\": \"GPU Memory(MB)\", \"type\": \"quantitative\"}}, \"transform\": [{\"fold\": [\"gpu_mem_mb\"]}]}, {\"mark\": {\"type\": \"point\", \"color\": \"#333\"}, \"encoding\": {\"x\": {\"axis\": {\"tickMinStep\": 1}, \"field\": \"node_id\", \"title\": \"Node ID\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"tickMinStep\": 100}, \"field\": \"gpu_mem_mb\", \"title\": \"GPU Memory(MB)\", \"type\": \"quantitative\"}}, \"transform\": [{\"fold\": [\"gpu_mem_mb\"]}]}, {\"data\": {\"name\": \"data-43088d309bbd52d25db51f30f1a97a32\"}, \"mark\": {\"type\": \"line\", \"color\": \"#7678ed\"}, \"encoding\": {\"x\": {\"axis\": {\"tickMinStep\": 1}, \"field\": \"node_id\", \"title\": \"Node ID\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"tickMinStep\": 100}, \"field\": \"gpu_mem_mb\", \"title\": \"GPU Memory(MB)\", \"type\": \"quantitative\"}}, \"transform\": [{\"fold\": [\"gpu_mem_mb\"]}]}, {\"data\": {\"name\": \"data-43088d309bbd52d25db51f30f1a97a32\"}, \"mark\": {\"type\": \"point\", \"color\": \"#333\"}, \"encoding\": {\"x\": {\"axis\": {\"tickMinStep\": 1}, \"field\": \"node_id\", \"title\": \"Node ID\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"tickMinStep\": 100}, \"field\": \"gpu_mem_mb\", \"title\": \"GPU Memory(MB)\", \"type\": \"quantitative\"}}, \"transform\": [{\"fold\": [\"gpu_mem_mb\"]}]}], \"data\": {\"name\": \"data-44fc900532c920d850e46bccf3f422d5\"}, \"height\": 900, \"title\": \"CUDA GPU Memory Usage: VGG19 Forwarding Phase with Gradient-Checkpointing Enabled\", \"transform\": [{\"fold\": [\"gpu_mem_mb\"]}], \"width\": 1500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-44fc900532c920d850e46bccf3f422d5\": [{\"node_id\": 0, \"gpu_mem_mb\": 1190.81}, {\"node_id\": 1, \"gpu_mem_mb\": 4563.61}, {\"node_id\": 2, \"gpu_mem_mb\": 4563.61}, {\"node_id\": 3, \"gpu_mem_mb\": 1686.3200000000002}, {\"node_id\": 4, \"gpu_mem_mb\": 3330.48}, {\"node_id\": 5, \"gpu_mem_mb\": 3330.48}, {\"node_id\": 6, \"gpu_mem_mb\": 1891.8400000000001}, {\"node_id\": 7, \"gpu_mem_mb\": 2713.92}, {\"node_id\": 8, \"gpu_mem_mb\": 2713.92}, {\"node_id\": 9, \"gpu_mem_mb\": 2713.92}, {\"node_id\": 10, \"gpu_mem_mb\": 2713.92}, {\"node_id\": 11, \"gpu_mem_mb\": 2405.64}, {\"node_id\": 12, \"gpu_mem_mb\": 2302.88}, {\"node_id\": 13, \"gpu_mem_mb\": 2302.88}, {\"node_id\": 14, \"gpu_mem_mb\": 2302.88}, {\"node_id\": 15, \"gpu_mem_mb\": 2302.88}, {\"node_id\": 16, \"gpu_mem_mb\": 2148.74}, {\"node_id\": 17, \"gpu_mem_mb\": 1994.6}, {\"node_id\": 18, \"gpu_mem_mb\": 1994.6}, {\"node_id\": 19, \"gpu_mem_mb\": 1994.6}, {\"node_id\": 20, \"gpu_mem_mb\": 1994.6}, {\"node_id\": 21, \"gpu_mem_mb\": 1904.6799999999998}], \"data-43088d309bbd52d25db51f30f1a97a32\": [{\"node_id\": 0, \"gpu_mem_mb\": 1096}, {\"node_id\": 1, \"gpu_mem_mb\": 2664}, {\"node_id\": 2, \"gpu_mem_mb\": 2664}, {\"node_id\": 3, \"gpu_mem_mb\": 1488}, {\"node_id\": 4, \"gpu_mem_mb\": 2272}, {\"node_id\": 5, \"gpu_mem_mb\": 2272}, {\"node_id\": 6, \"gpu_mem_mb\": 1684}, {\"node_id\": 7, \"gpu_mem_mb\": 2076}, {\"node_id\": 8, \"gpu_mem_mb\": 2076}, {\"node_id\": 9, \"gpu_mem_mb\": 2076}, {\"node_id\": 10, \"gpu_mem_mb\": 2076}, {\"node_id\": 11, \"gpu_mem_mb\": 1782}, {\"node_id\": 12, \"gpu_mem_mb\": 1880}, {\"node_id\": 13, \"gpu_mem_mb\": 1880}, {\"node_id\": 14, \"gpu_mem_mb\": 1880}, {\"node_id\": 15, \"gpu_mem_mb\": 1880}, {\"node_id\": 16, \"gpu_mem_mb\": 1733}, {\"node_id\": 17, \"gpu_mem_mb\": 1733}, {\"node_id\": 18, \"gpu_mem_mb\": 1733}, {\"node_id\": 19, \"gpu_mem_mb\": 1733}, {\"node_id\": 20, \"gpu_mem_mb\": 1733}, {\"node_id\": 21, \"gpu_mem_mb\": 1696}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "total = [\n",
    "    {\"node_id\": 0, \"gpu_mem_mb\": 1738.69}, # before forwarding.\n",
    "    {\"node_id\": 1, \"gpu_mem_mb\": 6755.65},\n",
    "    {\"node_id\": 2, \"gpu_mem_mb\": 10043.98},\n",
    "    {\"node_id\": 3, \"gpu_mem_mb\": 9632.94},\n",
    "    {\"node_id\": 4, \"gpu_mem_mb\": 12099.19},\n",
    "    {\"node_id\": 5, \"gpu_mem_mb\": 13743.36},\n",
    "    {\"node_id\": 6, \"gpu_mem_mb\": 13537.84},\n",
    "    {\"node_id\": 7, \"gpu_mem_mb\": 14770.97},\n",
    "    {\"node_id\": 8, \"gpu_mem_mb\": 15593.05},\n",
    "    {\"node_id\": 9, \"gpu_mem_mb\": 16415.14},\n",
    "    {\"node_id\":10, \"gpu_mem_mb\": 17237.22},\n",
    "    {\"node_id\":11, \"gpu_mem_mb\": 17134.46},\n",
    "    {\"node_id\":12, \"gpu_mem_mb\": 17751.03},\n",
    "    {\"node_id\":13, \"gpu_mem_mb\": 18162.08},\n",
    "    {\"node_id\":14, \"gpu_mem_mb\": 18573.12},\n",
    "    {\"node_id\":15, \"gpu_mem_mb\": 18984.17},\n",
    "    {\"node_id\":16, \"gpu_mem_mb\": 18932.79},\n",
    "    {\"node_id\":17, \"gpu_mem_mb\": 19086.93},\n",
    "    {\"node_id\":18, \"gpu_mem_mb\": 19189.70},\n",
    "    {\"node_id\":19, \"gpu_mem_mb\": 19292.46},\n",
    "    {\"node_id\":20, \"gpu_mem_mb\": 19395.23},\n",
    "    {\"node_id\":21, \"gpu_mem_mb\": 19382.38},\n",
    "]\n",
    "\n",
    "algo_predict = [\n",
    "    {\"node_id\": 0, \"gpu_mem_mb\": 548+548 }, # before forwarding.\n",
    "    {\"node_id\": 1, \"gpu_mem_mb\": 548+548+1568 },\n",
    "    {\"node_id\": 2, \"gpu_mem_mb\": 548+548+1568 },\n",
    "    {\"node_id\": 3, \"gpu_mem_mb\": 548+548+392 }, # pivot 1\n",
    "    {\"node_id\": 4, \"gpu_mem_mb\": 548+548+(392)+784 },\n",
    "    {\"node_id\": 5, \"gpu_mem_mb\": 548+548+(392)+784 },\n",
    "    {\"node_id\": 6, \"gpu_mem_mb\": 548+548+(392)+196 }, # pivot 2\n",
    "    {\"node_id\": 7, \"gpu_mem_mb\": 548+548+(392)+(196)+392 },\n",
    "    {\"node_id\": 8, \"gpu_mem_mb\": 548+548+(392)+(196)+392 },\n",
    "    {\"node_id\": 9, \"gpu_mem_mb\": 548+548+(392)+(196)+392 },\n",
    "    {\"node_id\":10, \"gpu_mem_mb\": 548+548+(392)+(196)+392 },\n",
    "    {\"node_id\":11, \"gpu_mem_mb\": 548+548+(392)+(196)+98 },\n",
    "    {\"node_id\":12, \"gpu_mem_mb\": 548+548+(392)+(196)+196 },\n",
    "    {\"node_id\":13, \"gpu_mem_mb\": 548+548+(392)+(196)+196 },\n",
    "    {\"node_id\":14, \"gpu_mem_mb\": 548+548+(392)+(196)+196 },\n",
    "    {\"node_id\":15, \"gpu_mem_mb\": 548+548+(392)+(196)+196 },\n",
    "    {\"node_id\":16, \"gpu_mem_mb\": 548+548+(392)+(196)+49 },\n",
    "    {\"node_id\":17, \"gpu_mem_mb\": 548+548+(392)+(196)+49 },\n",
    "    {\"node_id\":18, \"gpu_mem_mb\": 548+548+(392)+(196)+49 },\n",
    "    {\"node_id\":19, \"gpu_mem_mb\": 548+548+(392)+(196)+49 },\n",
    "    {\"node_id\":20, \"gpu_mem_mb\": 548+548+(392)+(196)+49 },\n",
    "    {\"node_id\":21, \"gpu_mem_mb\": 548+548+(392)+(196)+12 },\n",
    "]\n",
    "\n",
    "total_cp_algo = [\n",
    "    {\"node_id\": 0, \"gpu_mem_mb\": 1738.81-548}, # before forwarding.\n",
    "    {\"node_id\": 1, \"gpu_mem_mb\": 5111.61-548},\n",
    "    {\"node_id\": 2, \"gpu_mem_mb\": 5111.61-548},\n",
    "    {\"node_id\": 3, \"gpu_mem_mb\": 2234.32-548},\n",
    "    {\"node_id\": 4, \"gpu_mem_mb\": 3878.48-548},\n",
    "    {\"node_id\": 5, \"gpu_mem_mb\": 3878.48-548},\n",
    "    {\"node_id\": 6, \"gpu_mem_mb\": 2439.84-548},\n",
    "    {\"node_id\": 7, \"gpu_mem_mb\": 3261.92-548},\n",
    "    {\"node_id\": 8, \"gpu_mem_mb\": 3261.92-548},\n",
    "    {\"node_id\": 9, \"gpu_mem_mb\": 3261.92-548},\n",
    "    {\"node_id\":10, \"gpu_mem_mb\": 3261.92-548},\n",
    "    {\"node_id\":11, \"gpu_mem_mb\": 2953.64-548},\n",
    "    {\"node_id\":12, \"gpu_mem_mb\": 2850.88-548},\n",
    "    {\"node_id\":13, \"gpu_mem_mb\": 2850.88-548},\n",
    "    {\"node_id\":14, \"gpu_mem_mb\": 2850.88-548},\n",
    "    {\"node_id\":15, \"gpu_mem_mb\": 2850.88-548},\n",
    "    {\"node_id\":16, \"gpu_mem_mb\": 2696.74-548},\n",
    "    {\"node_id\":17, \"gpu_mem_mb\": 2542.60-548},\n",
    "    {\"node_id\":18, \"gpu_mem_mb\": 2542.60-548},\n",
    "    {\"node_id\":19, \"gpu_mem_mb\": 2542.60-548},\n",
    "    {\"node_id\":20, \"gpu_mem_mb\": 2542.60-548},\n",
    "    {\"node_id\":21, \"gpu_mem_mb\": 2452.68-548},\n",
    "]\n",
    "\n",
    "total_cp_na = [\n",
    "    {\"node_id\": 0, \"gpu_mem_mb\": 1681.824218}, # before forwarding.\n",
    "    {\"node_id\": 1, \"gpu_mem_mb\": 5111.09},\n",
    "    {\"node_id\": 2, \"gpu_mem_mb\": 3466.92},\n",
    "    {\"node_id\": 3, \"gpu_mem_mb\": 3877.96},\n",
    "    {\"node_id\": 4, \"gpu_mem_mb\": 5111.09},\n",
    "    {\"node_id\": 5, \"gpu_mem_mb\": 4289.00},\n",
    "    {\"node_id\": 6, \"gpu_mem_mb\": 4494.52},\n",
    "    {\"node_id\": 7, \"gpu_mem_mb\": 5111.09},\n",
    "    {\"node_id\": 8, \"gpu_mem_mb\": 4700.04},\n",
    "    {\"node_id\": 9, \"gpu_mem_mb\": 5522.13},\n",
    "    {\"node_id\":10, \"gpu_mem_mb\": 5522.13},\n",
    "    {\"node_id\":11, \"gpu_mem_mb\": 4802.80},\n",
    "    {\"node_id\":12, \"gpu_mem_mb\": 5213.85},\n",
    "    {\"node_id\":13, \"gpu_mem_mb\": 5008.33},\n",
    "    {\"node_id\":14, \"gpu_mem_mb\": 5419.37},\n",
    "    {\"node_id\":15, \"gpu_mem_mb\": 5419.37},\n",
    "    {\"node_id\":16, \"gpu_mem_mb\": 5059.71},\n",
    "    {\"node_id\":17, \"gpu_mem_mb\": 5162.47},\n",
    "    {\"node_id\":18, \"gpu_mem_mb\": 5111.09},\n",
    "    {\"node_id\":19, \"gpu_mem_mb\": 5213.85},\n",
    "    {\"node_id\":20, \"gpu_mem_mb\": 5213.85},\n",
    "    {\"node_id\":21, \"gpu_mem_mb\": 5124.32},\n",
    "]\n",
    "\n",
    "# Prediction by algo.\n",
    "# [1568, 1568, 392.0,\n",
    "#  784.0, 784.0, 196.0,\n",
    "#  392.0, 392.0, 392.0, 392.0,\n",
    "#  98.0, 196.0, 196.0, 196.0, 196.0,\n",
    "#  49.0, 49.0, 49.0, 49.0, 49.0, 12.0]\n",
    "# + weight_all.\n",
    "# 547.990966796875 MB = 76.365966796875 MB (conv) + ? MB (classifier)\n",
    "# pytorch_memlab:\n",
    "# Used Memory: 548.05M  Total Tensors: 143667240        \n",
    "\n",
    "df_total = pd.DataFrame(total)\n",
    "df_total_cp_algo = pd.DataFrame(total_cp_algo)\n",
    "df_total_cp_na = pd.DataFrame(total_cp_na)\n",
    "df_algo_predict = pd.DataFrame(algo_predict)\n",
    "# df_activation = pd.DataFrame(activation)\n",
    "\n",
    "l_total = alt.Chart(df_total).mark_line(color=\"#7d8597\").transform_fold(\n",
    "    ['gpu_mem_mb']\n",
    ").encode(\n",
    "    alt.X(\"node_id\", axis=alt.Axis(tickMinStep=1)).title(\"Node ID\"),\n",
    "    alt.Y(\"gpu_mem_mb\", axis=alt.Axis(tickMinStep=100)).title(\"GPU Memory(MB)\"),\n",
    ")\n",
    "\n",
    "\n",
    "l_total_cp_algo = alt.Chart(df_total_cp_algo).mark_line(color=\"#0ead69\").transform_fold(\n",
    "    ['gpu_mem_mb']\n",
    ").encode(\n",
    "    alt.X(\"node_id\", axis=alt.Axis(tickMinStep=1)).title(\"Node ID\"),\n",
    "    alt.Y(\"gpu_mem_mb\", axis=alt.Axis(tickMinStep=100)).title(\"GPU Memory(MB)\"),\n",
    ")\n",
    "\n",
    "\n",
    "l_total_cp_na = alt.Chart(df_total_cp_na).mark_line(color=\"#7678ed\").transform_fold(\n",
    "    ['gpu_mem_mb']\n",
    ").encode(\n",
    "    alt.X(\"node_id\", axis=alt.Axis(tickMinStep=1)).title(\"Node ID\"),\n",
    "    alt.Y(\"gpu_mem_mb\", axis=alt.Axis(tickMinStep=100)).title(\"GPU Memory(MB)\"),\n",
    ")\n",
    "\n",
    "\n",
    "l_algo_predict = alt.Chart(df_algo_predict).mark_line(color=\"#7678ed\").transform_fold(\n",
    "    ['gpu_mem_mb']\n",
    ").encode(\n",
    "    alt.X(\"node_id\", axis=alt.Axis(tickMinStep=1)).title(\"Node ID\"),\n",
    "    alt.Y(\"gpu_mem_mb\", axis=alt.Axis(tickMinStep=100)).title(\"GPU Memory(MB)\"),\n",
    ")\n",
    "\n",
    "# y_segment_cost = (\n",
    "#     alt.Chart().mark_rule(strokeDash=[12, 6], size=2).encode(y=alt.datum(822))\n",
    "# )\n",
    "\n",
    "# bar = line.mark_bar()\n",
    "point_total = l_total.mark_point(color=\"#333\")\n",
    "point_total_cp_algo = l_total_cp_algo.mark_point(color=\"#333\")\n",
    "point_total_cp_na = l_total_cp_na.mark_point(color=\"#333\")\n",
    "point_algo_predict = l_algo_predict.mark_point(color=\"#333\")\n",
    "\n",
    "(l_total_cp_algo + point_total_cp_algo\n",
    " # + l_total_cp_na + point_total_cp_na\n",
    " # + l_total + point_total\n",
    " + l_algo_predict + point_algo_predict\n",
    ").transform_fold(\n",
    "    ['gpu_mem_mb'],\n",
    ").properties(\n",
    "    title=\"CUDA GPU Memory Usage: VGG19 Forwarding Phase with Gradient-Checkpointing Enabled\",\n",
    "    width=1500,\n",
    "    height=900\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-paper)",
   "language": "python",
   "name": "pytorch-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
